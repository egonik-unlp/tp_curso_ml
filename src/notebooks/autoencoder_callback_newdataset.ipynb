{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Autoencoder.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/egonik-unlp/tp_curso_ml/blob/main/src/notebooks/autoencoder_callback_newdataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytMhZKgfLD9e",
        "outputId": "20091465-f2e9-459e-d008-15cb62ea95c7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import requests\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import normalize, MinMaxScaler\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww0MpD9YvDhd"
      },
      "source": [
        "codigo_numerico=requests.get(\"https://raw.githubusercontent.com/egonik-unlp/tp_curso_ml/main/src/notebooks/codigo_numerico.json\").json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy-iCvj0WYbG"
      },
      "source": [
        "codigo_numerico=requests.get('https://raw.githubusercontent.com/egonik-unlp/tp_curso_ml/d61d2cd55fe79750c892a739129de1e02ead2d29/src/pickle/json_files/codigo_blosum62.json').json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPGvGWF3M5ua",
        "outputId": "88cabf5e-7221-43c5-9531-d6e52eaf7199"
      },
      "source": [
        "%cd /content/drive/MyDrive/protein_classifier_with_locations/dataset_proteoma_full/\n",
        "proteome=np.load(\"proteome_short.npy\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/protein_classifier_with_locations/dataset_proteoma_full\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1-4wMEEQZtn"
      },
      "source": [
        "# scaler=MinMaxScaler()\n",
        "X_train_val, X_test=train_test_split(proteome)\n",
        "X_train, X_valid=train_test_split(X_train_val)\n",
        "\n",
        "# Por el momento voy a tratar de escalar manualmente, para evitar problemas de redondeo en la\n",
        "# conversi√≥n inversa\n",
        "\n",
        "# X_train_n=scaler.fit_transform(X_train)\n",
        "# X_valid_n=scaler.transform(X_valid)\n",
        "# X_test_n=scaler.transform(X_test)\n",
        "\n",
        "\n",
        "X_train_n=X_train/25 # el valor maximo del 'codigo numerico'\n",
        "X_valid_n=X_valid/25\n",
        "X_test_n=X_test/25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_DLMOxY--ex"
      },
      "source": [
        "# Reshapeo para que funcione en el AE\n",
        "X_train_bis=X_train_n.reshape(-1,2000,1)\n",
        "X_valid_bis=X_valid_n.reshape(-1,2000,1)\n",
        "X_test_bis=X_test_n.reshape(-1,2000,1)\n",
        "del X_train_n\n",
        "del X_valid_n\n",
        "del X_test_n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zi4bo0PSVXv",
        "outputId": "43fd2e02-47f1-41e9-9550-14fb941d8f25"
      },
      "source": [
        "X_train_bis.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56250, 2000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbDj1bLzNqLF",
        "outputId": "86af4baf-f65c-4ab2-ba00-8c0f73b70fb1"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "conv_encoder = keras.models.Sequential([\n",
        "keras.layers.Reshape([2000, 1], input_shape=[2000,1]),\n",
        "keras.layers.Conv1D(16, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
        "keras.layers.MaxPool1D(pool_size=2),\n",
        "keras.layers.Conv1D(32, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
        "keras.layers.MaxPool1D(pool_size=2),\n",
        "keras.layers.Conv1D(64, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
        "keras.layers.MaxPool1D(pool_size=2)\n",
        "])\n",
        "\n",
        "\n",
        "conv_decoder = keras.models.Sequential([\n",
        "keras.layers.Conv1DTranspose(32, kernel_size=3, strides=2, padding=\"same\",\n",
        "activation=\"selu\",\n",
        "input_shape=[250, 64]),\n",
        "keras.layers.Conv1DTranspose(16, kernel_size=3, strides=2, padding=\"same\",\n",
        "activation=\"selu\"),\n",
        "keras.layers.Conv1DTranspose(1, kernel_size=3, strides=2, padding=\"same\",\n",
        "activation=\"sigmoid\"),\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])\n",
        "conv_ae.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential (Sequential)      (None, 250, 64)           7840      \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 2000, 1)           7777      \n",
            "=================================================================\n",
            "Total params: 15,617\n",
            "Trainable params: 15,617\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpHqdFXpbaKw"
      },
      "source": [
        "nums_codes={v:k for k,v in codigo_numerico.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWGyEt9ScWlb"
      },
      "source": [
        "def unpad(query, target):\n",
        "  try:\n",
        "    idx=np.where(query==0)[0][-1] + 1\n",
        "  except IndexError:\n",
        "    idx=0\n",
        "  return query[idx:], target[idx:]\n",
        "  \n",
        "class ProteinEvaluator(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}, protein_code=nums_codes):\n",
        "    if epoch%5 == 0 and epoch!=0:\n",
        "      predictions=self.model.predict(X_valid_bis)\n",
        "      pred_seqs=[]\n",
        "      for n,(query, target) in enumerate(zip(X_valid_bis.reshape(-1,2000), predictions.reshape(-1,2000))):\n",
        "        qry,tgt=unpad(query,target)\n",
        "        del qry\n",
        "        pred_seqs.append(tgt)\n",
        "      compressed_proteins=[''.join(np.vectorize(lambda x:nums_codes.get(round(x*25),'X'))(seq)) for seq in pred_seqs]\n",
        "      with open('/content/drive/MyDrive/protein_classifier_with_locations/autoencoder/sequences_checkpoints/pred_seqs_epoch_{}.json'.format(epoch), 'w') as file:\n",
        "        json.dump(compressed_proteins, file)\n",
        "pe=ProteinEvaluator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2U6ooYqhTry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b65161c-3b08-46a5-a6bf-fcd1f8d6bbd8"
      },
      "source": [
        "0%5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KCvLswFhTlT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5noAtEGbXLx"
      },
      "source": [
        "class CustomSaver(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch %5 == 0:  # or save after some epoch, each k-th epoch etc.\n",
        "            self.model.save('/content/drive/MyDrive/protein_classifier_with_locations/autoencoder/autoencoder_prot_{}.h5'.format(epoch))\n",
        "cs=CustomSaver()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57bJtD7Q8yCd",
        "outputId": "5ab401ab-626c-43ee-f4ee-cdeef5416590"
      },
      "source": [
        "conv_ae.compile(loss=\"binary_crossentropy\",\n",
        "optimizer=keras.optimizers.SGD(learning_rate=1.5))\n",
        "# checkpoint = keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/protein_classifier_with_locations/autoencoder/autoencoder_prot_{epoch:08d}.h5', period=5)\n",
        "history = conv_ae.fit(X_train_bis, X_train_bis, epochs=150,\n",
        "  validation_data=[X_valid_bis, X_valid_bis], callbacks=[pe])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "1758/1758 [==============================] - 50s 11ms/step - loss: 0.0986 - val_loss: 0.0000e+00\n",
            "Epoch 2/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0855 - val_loss: 0.0000e+00\n",
            "Epoch 3/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0836 - val_loss: 0.0000e+00\n",
            "Epoch 4/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0827 - val_loss: 0.0000e+00\n",
            "Epoch 5/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0822 - val_loss: 0.0000e+00\n",
            "Epoch 6/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0818 - val_loss: 0.0000e+00\n",
            "Epoch 7/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0816 - val_loss: 0.0000e+00\n",
            "Epoch 8/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0814 - val_loss: 0.0000e+00\n",
            "Epoch 9/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0812 - val_loss: 0.0000e+00\n",
            "Epoch 10/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0811 - val_loss: 0.0000e+00\n",
            "Epoch 11/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0810 - val_loss: 0.0000e+00\n",
            "Epoch 12/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0809 - val_loss: 0.0000e+00\n",
            "Epoch 13/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0808 - val_loss: 0.0000e+00\n",
            "Epoch 14/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0807 - val_loss: 0.0000e+00\n",
            "Epoch 15/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0806 - val_loss: 0.0000e+00\n",
            "Epoch 16/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0806 - val_loss: 0.0000e+00\n",
            "Epoch 17/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0805 - val_loss: 0.0000e+00\n",
            "Epoch 18/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0804 - val_loss: 0.0000e+00\n",
            "Epoch 19/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0804 - val_loss: 0.0000e+00\n",
            "Epoch 20/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0803 - val_loss: 0.0000e+00\n",
            "Epoch 21/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0803 - val_loss: 0.0000e+00\n",
            "Epoch 22/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0802 - val_loss: 0.0000e+00\n",
            "Epoch 23/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0802 - val_loss: 0.0000e+00\n",
            "Epoch 24/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0801 - val_loss: 0.0000e+00\n",
            "Epoch 25/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0801 - val_loss: 0.0000e+00\n",
            "Epoch 26/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0801 - val_loss: 0.0000e+00\n",
            "Epoch 27/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0800 - val_loss: 0.0000e+00\n",
            "Epoch 28/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0800 - val_loss: 0.0000e+00\n",
            "Epoch 29/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0800 - val_loss: 0.0000e+00\n",
            "Epoch 30/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0799 - val_loss: 0.0000e+00\n",
            "Epoch 31/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0799 - val_loss: 0.0000e+00\n",
            "Epoch 32/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0799 - val_loss: 0.0000e+00\n",
            "Epoch 33/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0799 - val_loss: 0.0000e+00\n",
            "Epoch 34/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0798 - val_loss: 0.0000e+00\n",
            "Epoch 35/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0798 - val_loss: 0.0000e+00\n",
            "Epoch 36/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0798 - val_loss: 0.0000e+00\n",
            "Epoch 37/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0798 - val_loss: 0.0000e+00\n",
            "Epoch 38/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0797 - val_loss: 0.0000e+00\n",
            "Epoch 39/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0797 - val_loss: 0.0000e+00\n",
            "Epoch 40/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0797 - val_loss: 0.0000e+00\n",
            "Epoch 41/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0797 - val_loss: 0.0000e+00\n",
            "Epoch 42/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0797 - val_loss: 0.0000e+00\n",
            "Epoch 43/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0796 - val_loss: 0.0000e+00\n",
            "Epoch 44/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0796 - val_loss: 0.0000e+00\n",
            "Epoch 45/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0796 - val_loss: 0.0000e+00\n",
            "Epoch 46/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0796 - val_loss: 0.0000e+00\n",
            "Epoch 47/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0796 - val_loss: 0.0000e+00\n",
            "Epoch 48/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0796 - val_loss: 0.0000e+00\n",
            "Epoch 49/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0795 - val_loss: 0.0000e+00\n",
            "Epoch 50/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0795 - val_loss: 0.0000e+00\n",
            "Epoch 51/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0795 - val_loss: 0.0000e+00\n",
            "Epoch 52/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0795 - val_loss: 0.0000e+00\n",
            "Epoch 53/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0795 - val_loss: 0.0000e+00\n",
            "Epoch 54/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0795 - val_loss: 0.0000e+00\n",
            "Epoch 55/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0795 - val_loss: 0.0000e+00\n",
            "Epoch 56/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0795 - val_loss: 0.0000e+00\n",
            "Epoch 57/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0794 - val_loss: 0.0000e+00\n",
            "Epoch 58/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0794 - val_loss: 0.0000e+00\n",
            "Epoch 59/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0794 - val_loss: 0.0000e+00\n",
            "Epoch 60/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0794 - val_loss: 0.0000e+00\n",
            "Epoch 61/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0794 - val_loss: 0.0000e+00\n",
            "Epoch 62/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0794 - val_loss: 0.0000e+00\n",
            "Epoch 63/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0794 - val_loss: 0.0000e+00\n",
            "Epoch 64/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0794 - val_loss: 0.0000e+00\n",
            "Epoch 65/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0794 - val_loss: 0.0000e+00\n",
            "Epoch 66/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0794 - val_loss: 0.0000e+00\n",
            "Epoch 67/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0793 - val_loss: 0.0000e+00\n",
            "Epoch 68/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0793 - val_loss: 0.0000e+00\n",
            "Epoch 69/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0793 - val_loss: 0.0000e+00\n",
            "Epoch 70/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0793 - val_loss: 0.0000e+00\n",
            "Epoch 71/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0793 - val_loss: 0.0000e+00\n",
            "Epoch 72/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0793 - val_loss: 0.0000e+00\n",
            "Epoch 73/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0793 - val_loss: 0.0000e+00\n",
            "Epoch 74/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0793 - val_loss: 0.0000e+00\n",
            "Epoch 75/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0793 - val_loss: 0.0000e+00\n",
            "Epoch 76/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0793 - val_loss: 0.0000e+00\n",
            "Epoch 77/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0793 - val_loss: 0.0000e+00\n",
            "Epoch 78/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0793 - val_loss: 0.0000e+00\n",
            "Epoch 79/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0793 - val_loss: 0.0000e+00\n",
            "Epoch 80/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0793 - val_loss: 0.0000e+00\n",
            "Epoch 81/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0793 - val_loss: 0.0000e+00\n",
            "Epoch 82/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 83/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 84/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 85/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 86/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 87/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 88/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 89/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 90/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 91/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 92/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 93/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 94/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 95/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 96/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 97/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 98/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 99/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 100/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 101/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 102/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 103/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 104/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 105/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 106/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 107/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0792 - val_loss: 0.0000e+00\n",
            "Epoch 108/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 109/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 110/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 111/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 112/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 113/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 114/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 115/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 116/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 117/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 118/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 119/150\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 120/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 121/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 122/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 123/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 124/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 125/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 126/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 127/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 128/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 129/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 130/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 131/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 132/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 133/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 134/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 135/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 136/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 137/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 138/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 139/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 140/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 141/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 142/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 143/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 144/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 145/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0791 - val_loss: 0.0000e+00\n",
            "Epoch 146/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0790 - val_loss: 0.0000e+00\n",
            "Epoch 147/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0790 - val_loss: 0.0000e+00\n",
            "Epoch 148/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0790 - val_loss: 0.0000e+00\n",
            "Epoch 149/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0790 - val_loss: 0.0000e+00\n",
            "Epoch 150/150\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0790 - val_loss: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-VWgQHklCXZ"
      },
      "source": [
        "np.save('/content/drive/MyDrive/protein_classifier_with_locations/autoencoder/sequences_checkpoints/arrays/X_valid_bis', X_valid_bis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZF6p9WbitpM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a18c2a9-9860-4daa-a0bf-7d09a38485f3"
      },
      "source": [
        "!cd /content/drive/MyDrive/protein_classifier_with_locations/autoencoder/sequences_checkpoints/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 0: cd: /content/drive/MyDrive/protein_classifier_with_locations/autoencoder/sequences_checkpoints/: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69zma5BJDp8p"
      },
      "source": [
        "def unpad(query, target):\n",
        "  try:\n",
        "    idx=np.where(query==0)[0][-1] + 1\n",
        "  except IndexError:\n",
        "    idx=0\n",
        "  return query[idx:], target[idx:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgn7kHaDFfwi",
        "outputId": "b0b1b898-3924-4d3c-86f9-4123d6dca72d"
      },
      "source": [
        "rpts=4\n",
        "pred_seqs=[]\n",
        "original_seqs=[]\n",
        "\n",
        "for i in range(rpts):\n",
        "  history = conv_ae.fit(X_train_bis, X_train_bis, epochs=10,\n",
        "  validation_data=[X_valid_bis, X_valid_bis])\n",
        "  scores=np.zeros(X_test_bis.shape[0])\n",
        "  predictions=conv_ae.predict(X_test_bis)\n",
        "  for n,(query, target) in enumerate(zip(X_test_bis.reshape(-1,2000), predictions.reshape(-1,2000))):\n",
        "    qry,tgt=unpad(query,target)\n",
        "    original_seqs.append(qry)\n",
        "    del qry\n",
        "    pred_seqs.append(tgt)\n",
        "  del predictions\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1758/1758 [==============================] - 50s 11ms/step - loss: 0.0997 - val_loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0859 - val_loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0839 - val_loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0829 - val_loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0823 - val_loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0819 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0816 - val_loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0814 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0812 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0810 - val_loss: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0809 - val_loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0808 - val_loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0807 - val_loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0806 - val_loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0805 - val_loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0804 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0804 - val_loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0803 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0802 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0802 - val_loss: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0801 - val_loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0801 - val_loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1758/1758 [==============================] - 20s 11ms/step - loss: 0.0801 - val_loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0800 - val_loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0800 - val_loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0800 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0799 - val_loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0799 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0799 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0799 - val_loss: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0798 - val_loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0798 - val_loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0798 - val_loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0798 - val_loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0797 - val_loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0797 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0797 - val_loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0797 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0797 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1758/1758 [==============================] - 19s 11ms/step - loss: 0.0797 - val_loss: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0gV1d6WHYhm"
      },
      "source": [
        "original_seqs=[seq for seq in X_test_bis.reshape(-1,2000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIYgyfET3bgc"
      },
      "source": [
        "nums_codes={v:k for k,v in codigo_numerico.items()} \n",
        "# compressed_proteins=[''.join(np.vectorize(lambda x:nums_codes.get(round(x*25),'X'))(seq)) for seq in pred_seqs]\n",
        "original_proteins=[''.join(np.vectorize(lambda x:nums_codes.get(round(x*25),'X'))(seq)) for seq in original_seqs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjxZssIoS3jm",
        "outputId": "461d5c4a-416f-4a16-e02f-ae106662fa3f"
      },
      "source": [
        "len(original_proteins)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhHuHfIhyEUn"
      },
      "source": [
        "# np.save('/content/drive/MyDrive/protein_classifier_with_locations/autoencoder/predictions',predictions)\n",
        "np.save('/content/drive/MyDrive/protein_classifier_with_locations/autoencoder/compressed_proteins',compressed_proteins)\n",
        "np.save('/content/drive/MyDrive/protein_classifier_with_locations/autoencoder/original_proteins', original_proteins)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}